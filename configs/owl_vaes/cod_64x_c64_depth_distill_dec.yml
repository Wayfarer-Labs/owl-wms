model:
  model_id: distill_vae
  sample_size: [360,640]
  channels: 3
  latent_size: 8
  latent_channels: 64

  encoder_blocks_per_stage: [1, 1, 1, 1, 1]
  decoder_blocks_per_stage: [1, 1, 1, 1, 1]

  ch_0: 96
  ch_max: 1536

train:
  trainer_id: distill_dec
  data_id: s3_cod_features
  data_kwargs:
    bucket_name: cod-raw-360p-30fs
    prefix: depth-and-raw

  target_batch_size: 256
  batch_size: 32

  epochs: 200

  opt: AdamW
  opt_kwargs:
    lr: 2.0e-4
    weight_decay: 1.0e-4
    betas: [0.9, 0.95]
    eps: 1.0e-15

  lpips_type: convnext
  loss_weights:
    l2: 1.0
    lpips: 12.0
    gan: 0.0
    feature_matching: 0.0

  scheduler: LinearWarmup
  scheduler_kwargs:
    warmup_steps: 1500
    min_lr: 1.5e-5

  checkpoint_dir: checkpoints/cod_64x_distill_dec
  resume_ckpt: null

  sample_interval: 1000
  save_interval: 5000

  teacher_cfg: configs/cod_64x_depth_v3.yml
  teacher_ckpt: ./cod_64x_depth_85k.pt

  latent_scale: 1.0

wandb:
  name: ${env:WANDB_USER_NAME}
  project: new_vaes
  run_name: 64x_depth_c64_distill_dec