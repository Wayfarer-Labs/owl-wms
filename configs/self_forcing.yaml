model:
  model_id: game_rft_audio
  sample_size: 4
  channels: 128
  audio_channels: 64
  n_layers: 25
  n_heads: 24
  d_model: 1536
  tokens_per_frame: 17
  n_buttons: 11
  n_mouse_axes: 2
  cfg_prob: 0.1
  context_length: 32
  n_frames: 60  # n_frames - context_length is how many frames we generate at once
  causal: false          # bidirectional teacher; set true for the student

train:
  trainer_id: self_forcing
  n_steps: 20
  frame_gradient_cutoff: 28 # TODO set this carefully in case it interferes with context length and num_gen_frames
  latent_shape: [128, 4, 4]
  scheduler: constant
  scheduler_kwargs:
    factor: 1.0
    total_iters: 1

  max_grad_norm: 5.0
  # ---------- data ----------
  data_id: cod_s3_audio
  data_kwargs:
    window_length: 60
    bucket_name: cod-data-latent-360x640to4x4

  # ---------- batching ----------
  target_batch_size: 64     # effective (across GPUs Ã— grad-accum)
  batch_size: 8     # clips / GPU
  epochs: 200

  # ---------- optimizer ----------
  opt: AdamW
  opt_kwargs:
    lr: 2.0e-6            # made this up TODO check 
    weight_decay: 0.01     # made this up
    eps: 1.0e-8           # paper value
    betas: [0.0, 0.999]   # paper value


  # ---------- checkpoints ----------
  checkpoint_dir: /mnt/data/checkpoints/self-forcing/
  teacher_ckpt: /mnt/data/checkpoints/av_huge/av_huge_1b_step205k_ema.pt
  student_ckpt: null
  critic_ckpt: null

  # ---------- logging / sampling ----------
  log_interval: 1
  sample_interval: 25
  save_interval: 100
  n_samples: 8

  # ---------- VAE ----------
  vae_id: null
  vae_batch_size: 4
  vae_scale: 0.13
  vae_cfg_path: configs/owl_vaes/cod_128x.yml
  vae_ckpt_path: /mnt/data/checkpoints/owl_vaes/cod_128x_30k_ema.pt

  audio_vae_id: null
  audio_vae_batch_size: 4
  audio_vae_scale: 0.17
  audio_vae_cfg_path: configs/owl_vaes/cod_audio.yml
  audio_vae_ckpt_path: /mnt/data/checkpoints/audio_ae/cod_audio_20k_ema.pt

wandb:
  name: samibg
  project: video_world_models
  run_name: self_forcing_360p4x4
