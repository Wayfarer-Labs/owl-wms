# Config for a simple 256 -> 16 autoencoder
model:
  model_id: game_rft
  sample_size: 4
  channels: 128
  
  n_layers: 13
  n_heads: 16
  d_model: 1024

  tokens_per_frame: 16
  n_buttons: 11
  n_mouse_axes: 2

  cfg_prob: 0.1
  n_frames: 30

  causal: false

train:
  trainer_id: rft
  data_id: cod_s3
  data_kwargs:
    window_length: 30
    bucket_name: cod-data-latent-360x640to4x4
    include_keyframe: false

  target_batch_size: 256
  batch_size: 32

  epochs: 200

  opt: Muon
  opt_kwargs:
    lr: 1.0e-3
    momentum: 0.95
    adamw_lr: 1.0e-4
    adamw_wd: 1.0e-4
    adamw_eps: 1.0e-15
    adamw_betas: [0.9, 0.95]
    adamw_keys: [core.proj_in, core.proj_out.proj]

  scheduler: null

  checkpoint_dir: checkpoints/360p

  sample_interval: 1000
  save_interval: 5000

  sampler_id: window
  sampler_kwargs:
    n_steps: 10
    cfg_scale: 1.3
    window_length: 30
    num_frames: 60
    noise_prev: 0.2
    only_return_generated: false

  n_samples: 8

  vae_id: 720pr3dc
  vae_batch_size: 4
  vae_scale: 0.13
  vae_cfg_path: configs/owl_vaes/cod_128x.yml
  vae_ckpt_path: checkpoints/owl_vaes/cod_128x_30k_ema.pt

wandb:
  name: shahbuland
  project: video_models
  run_name: v3